got you — here’s a clean **YOLO11** project you can copy-paste to another AI or teammate. It’s minimal, GPU-ready, and expects you to add your own dataset.

---

### `src/train_model.py`

```python
"""
train_model.py — Train YOLO11 on your dataset.
Usage:
  python src/train_model.py --data data/dataset/data.yaml --model yolo11n.pt --epochs 50 --batch 16 --imgsz 640 --name cylinder_detector
"""
from pathlib import Path
import argparse
import torch
from ultralytics import YOLO

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--data", type=str, default="data/dataset/data.yaml")
    ap.add_argument("--model", type=str, default="yolo11n.pt")
    ap.add_argument("--epochs", type=int, default=50)
    ap.add_argument("--batch", type=int, default=16)
    ap.add_argument("--imgsz", type=int, default=640)
    ap.add_argument("--name", type=str, default="cylinder_detector")
    args = ap.parse_args()

    device = 0 if torch.cuda.is_available() else "cpu"
    print(f"Training on: {'cuda' if device == 0 else 'cpu'}")
    if device == "cpu":
        print("⚠️ CPU training is slow. Install a CUDA build of PyTorch for speed.")

    data_yaml = Path(args.data)
    if not data_yaml.exists():
        raise FileNotFoundError(f"data.yaml not found: {data_yaml.resolve()}")

    model = YOLO(args.model)
    model.train(
        data=str(data_yaml),
        epochs=args.epochs,
        imgsz=args.imgsz,
        batch=args.batch,
        device=device,
        project="runs/train",
        name=args.name,
        exist_ok=True,
        deterministic=True,
        verbose=True,
        patience=30,
    )
    best = Path("runs") / "train" / args.name / "weights" / "best.pt"
    print("✅ Training complete.")
    print("Best weights:", best.resolve())

if __name__ == "__main__":
    main()
```

---

### `src/complete_system.py`

```python
"""
complete_system.py — Real-time detector with stability filter (K frames), YOLO11.
Usage:
  python src/complete_system.py --weights runs/train/cylinder_detector/weights/best.pt --source 0 --conf 0.5
"""
import argparse, time
from pathlib import Path
import cv2, torch
from ultralytics import YOLO

class KFramesValidator:
    def __init__(self, k=10, min_ratio=0.7):
        self.k, self.min_ratio = k, min_ratio
        self.hist = []
    def update(self, is_positive: bool) -> bool:
        self.hist.append(1 if is_positive else 0)
        if len(self.hist) > self.k: self.hist.pop(0)
        if len(self.hist) < self.k: return False
        return sum(self.hist) / float(self.k) >= self.min_ratio

def run(weights, source=0, conf=0.5, k=10, min_ratio=0.7, use_directshow=True):
    device = 0 if torch.cuda.is_available() else "cpu"
    print(f"[complete_system] device = {'cuda' if device==0 else 'cpu'}")
    model = YOLO(weights)
    validator = KFramesValidator(k=k, min_ratio=min_ratio)

    flag = cv2.CAP_DSHOW if use_directshow and isinstance(source, int) else 0
    cap = cv2.VideoCapture(source, flag) if isinstance(source, int) else cv2.VideoCapture(source)
    if not cap.isOpened():
        print(f"⚠️ Could not open source: {source}"); return

    Path("screenshots").mkdir(exist_ok=True, parents=True)
    print("Press 'q' to quit, 's' to save frame.")
    while True:
        ok, frame = cap.read()
        if not ok: print("⚠️ Cannot read frame."); break
        r = model.predict(source=frame, conf=conf, device=device, verbose=False)[0]
        annotated = r.plot() if hasattr(r, "plot") else frame
        has_det = (getattr(r, "boxes", None) is not None) and len(r.boxes) > 0
        stable = validator.update(has_det)
        h, w = annotated.shape[:2]
        status = f"STABLE: {'YES' if stable else 'NO'}"
        cv2.putText(annotated, status, (10, h - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.8,
                    (0,255,0) if stable else (0,0,255), 2)
        cv2.imshow("Gas Cylinder Detection (YOLO11)", annotated)
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'): break
        if key == ord('s'):
            out = Path("screenshots") / f"shot_{int(time.time())}.jpg"
            cv2.imwrite(str(out), annotated); print(f"[saved] {out.resolve()}")

    cap.release(); cv2.destroyAllWindows()

if __name__ == "__main__":
    ap = argparse.ArgumentParser()
    ap.add_argument("--weights", type=str, default="runs/train/cylinder_detector/weights/best.pt")
    ap.add_argument("--source", type=str, default="0")
    ap.add_argument("--conf", type=float, default=0.5)
    ap.add_argument("--k", type=int, default=10)
    ap.add_argument("--min_ratio", type=float, default=0.7)
    ap.add_argument("--directshow", action="store_true")
    args = ap.parse_args()
    src = int(args.source) if args.source.isdigit() else args.source
    run(args.weights, source=src, conf=args.conf, k=args.k, min_ratio=args.min_ratio, use_directshow=args.directshow)
```

---

### `src/yolo_detector.py`

```python
"""
yolo_detector.py — Minimal YOLO11 wrapper for quick tests.
Usage:
  python src/yolo_detector.py --weights runs/train/cylinder_detector/weights/best.pt --image path/to/img.jpg
  python src/yolo_detector.py --weights runs/train/cylinder_detector/weights/best.pt --webcam
"""
import argparse
from pathlib import Path
import cv2, torch
from ultralytics import YOLO

def detect_image(model, image_path, device, conf):
    img = cv2.imread(str(image_path))
    if img is None: print(f"⚠️ Cannot read image: {image_path}"); return
    r = model.predict(source=img, device=device, conf=conf, verbose=False)[0]
    out = r.plot() if hasattr(r, "plot") else img
    out_dir = Path("runs") / "detect" / "preview"; out_dir.mkdir(parents=True, exist_ok=True)
    out_path = out_dir / Path(image_path).name
    cv2.imwrite(str(out_path), out)
    print(f"[saved] {out_path.resolve()} (detections={len(getattr(r,'boxes',[]))})")

def detect_webcam(model, device, conf):
    cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)
    if not cap.isOpened(): print("⚠️ Could not open webcam 0"); return
    print("[webcam] Press 'q' to quit")
    while True:
        ok, frame = cap.read()
        if not ok: break
        r = model.predict(source=frame, device=device, conf=conf, verbose=False)[0]
        out = r.plot() if hasattr(r, "plot") else frame
        cv2.imshow("YOLO11 Detector", out)
        if cv2.waitKey(1) & 0xFF == ord('q'): break
    cap.release(); cv2.destroyAllWindows()

if __name__ == "__main__":
    ap = argparse.ArgumentParser()
    ap.add_argument("--weights", type=str, default="runs/train/cylinder_detector/weights/best.pt")
    ap.add_argument("--image", type=str, default=None)
    ap.add_argument("--webcam", action="store_true")
    ap.add_argument("--conf", type=float, default=0.5)
    args = ap.parse_args()

    device = 0 if torch.cuda.is_available() else "cpu"
    print(f"[yolo_detector] device = {'cuda' if device==0 else 'cpu'}")
    model = YOLO(args.weights)

    if args.webcam: detect_webcam(model, device, args.conf)
    elif args.image: detect_image(model, args.image, device, args.conf)
    else: print("Provide --image or --webcam")
```

---

### `src/test_gpu.py`

```python
"""
test_gpu.py — Verify CUDA is available and a YOLO11 forward pass works.
"""
import torch, numpy as np
from ultralytics import YOLO

def main():
    print("torch:", torch.__version__)
    print("cuda available?:", torch.cuda.is_available())
    if torch.cuda.is_available():
        print("cuda device count:", torch.cuda.device_count())
        print("cuda device name:", torch.cuda.get_device_name(0))
    else:
        print("⚠️ No CUDA detected by PyTorch. Install CUDA build of torch/driver.")
    try:
        model = YOLO("yolo11n.pt")
        img = (np.random.rand(640, 640, 3) * 255).astype("uint8")
        device = 0 if torch.cuda.is_available() else "cpu"
        _ = model.predict(source=img, device=device, conf=0.25, verbose=False)
        print("✅ YOLO11 forward pass worked on", "cuda:0" if device == 0 else "cpu")
    except Exception as e:
        print("❌ YOLO quick test failed:", e)

if __name__ == "__main__":
    main()
```

---

### `src/test_model.py`

```python
"""
test_model.py — Smoke test for your trained YOLO11 weights.
"""
import argparse, sys
from pathlib import Path
import cv2, torch
from ultralytics import YOLO

def summarize(r):
    n = 0 if getattr(r, "boxes", None) is None else len(r.boxes)
    names = r.names if hasattr(r, "names") else {}
    classes, confs = [], []
    for i in range(n):
        cid = int(r.boxes.cls[i].item())
        classes.append(names.get(cid, str(cid)))
        confs.append(float(r.boxes.conf[i].item()))
    return n, classes, confs

def test_on_image(model, image_path, device, conf):
    img = cv2.imread(str(image_path))
    if img is None: print(f"⚠️ Cannot read image: {image_path}"); sys.exit(1)
    r = model.predict(source=img, device=device, conf=conf, save=True, verbose=False)[0]
    n, classes, confs = summarize(r)
    print(f"[result] detections={n}")
    for i, (c, s) in enumerate(zip(classes, confs), 1):
        print(f"  #{i}: {c} @ {s:.3f}")
    print(f"[saved] annotated => {r.save_dir}")

def test_on_webcam(model, device, conf):
    cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)
    if not cap.isOpened(): print("⚠️ Could not open webcam 0"); return
    print("[webcam] Press 'q' to quit")
    while True:
        ok, frame = cap.read()
        if not ok: break
        r = model.predict(source=frame, device=device, conf=conf, verbose=False)[0]
        out = r.plot() if hasattr(r, "plot") else frame
        cv2.imshow("test_model (YOLO11)", out)
        if cv2.waitKey(1) & 0xFF == ord('q'): break
    cap.release(); cv2.destroyAllWindows()

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--weights", type=str, required=True)
    ap.add_argument("--image", type=str, default=None)
    ap.add_argument("--webcam", action="store_true")
    ap.add_argument("--conf", type=float, default=0.5)
    args = ap.parse_args()

    device = 0 if torch.cuda.is_available() else "cpu"
    print(f"[env] torch={torch.__version__}  cuda? {torch.cuda.is_available()}  device={device}")
    print(f"[load] weights: {args.weights}")
    model = YOLO(args.weights)

    if args.webcam: test_on_webcam(model, device, args.conf)
    elif args.image: test_on_image(model, Path(args.image), device, args.conf)
    else: print("Provide --image or --webcam")

if __name__ == "__main__":
    main()
```

---

### `src/opencv_detector.py` (optional baseline)

```python
"""
opencv_detector.py — Baseline red-cylinder heuristic with HSV + aspect ratio.
"""
import cv2, numpy as np

class CylinderDetectorBasic:
    def __init__(self):
        self.lower_red1 = np.array([0, 120, 70])
        self.upper_red1 = np.array([10, 255, 255])
        self.lower_red2 = np.array([170, 120, 70])
        self.upper_red2 = np.array([180, 255, 255])
        self.min_area = 5000

    def detect(self, img):
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        mask1 = cv2.inRange(hsv, self.lower_red1, self.upper_red1)
        mask2 = cv2.inRange(hsv, self.lower_red2, self.upper_red2)
        mask = cv2.bitwise_or(mask1, mask2)
        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, np.ones((5,5),np.uint8), iterations=2)
        contours,_ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        boxes=[]
        for c in contours:
            if cv2.contourArea(c) < self.min_area: continue
            x,y,w,h = cv2.boundingRect(c)
            ar = h / float(w + 1e-6)
            if 1.2 <= ar <= 4.5: boxes.append((x,y,x+w,y+h))
        for (x1,y1,x2,y2) in boxes:
            cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),2)
            cv2.putText(img,"cylinder?",(x1,max(20,y1-10)),cv2.FONT_HERSHEY_SIMPLEX,0.6,(0,255,0),2)
        return img, len(boxes) > 0
```

---

### `requirements.txt`

```
# Torch is installed separately so you can choose CPU or CUDA build
ultralytics
opencv-python
numpy
pyyaml
matplotlib
tqdm
```

### `setup_gpu.ps1` (Windows, NVIDIA)

```powershell
python -m pip install --upgrade pip setuptools wheel
python -m pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install -r requirements.txt
```

### `data/dataset/data.yaml` (example)

```yaml
path: data/dataset
train: train/images
val: val/images
test: test/images
names:
  0: cylinder
nc: 1
```

---

### Quick README (to include in the zip you send)

* Create venv & install:

```powershell
py -3.10 -m venv venv
.\venv\Scripts\Activate.ps1
.\setup_gpu.ps1   # or install CPU torch from pytorch.org if no NVIDIA GPU
```

* Add dataset under `data/dataset/...` and edit `data.yaml` if needed.
* Train:

```powershell
python src/train_model.py --data data/dataset/data.yaml --model yolo11n.pt --epochs 50 --batch 16 --imgsz 640 --name cylinder_detector
```

* Test:

```powershell
python src/test_model.py --weights runs/train/cylinder_detector/weights/best.pt --image data/dataset/val/images/sample.jpg
python src/test_model.py --weights runs/train/cylinder_detector/weights/best.pt --webcam
```

* Live app:

```powershell
python src/complete_system.py --weights runs/train/cylinder_detector/weights/best.pt --source 0 --conf 0.5
```

Want me to also bundle these into a **single zip** again so you can attach it directly?
